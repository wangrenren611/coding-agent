# 构建有效AI代理 - 深度分析

> 原文来源：[Building Effective Agents - Anthropic Engineering](https://www.anthropic.com/engineering/building-effective-agents)
> 发布日期：2024年12月19日

---

## 文章概述

本文基于 Anthropic 与数十个跨行业团队合作构建 LLM 代理的实战经验，总结出：**最成功的实现往往使用简单、可组合的模式，而非复杂的框架**。文章分享了从客户合作和自身构建代理中学到的经验，为开发者提供构建有效代理的实用建议。

---

## 核心观点

1. **简单优于复杂**：成功的实现不依赖复杂框架或专用库，而是基于简单、可组合的模式
2. **架构分类**：将代理性系统分为两类架构模式——工作流（Workflows）和代理（Agents）
3. **渐进式复杂性**：从最简单的解决方案开始，仅在需要时增加复杂性
4. **测量驱动迭代**：通过性能测量和实施迭代来验证复杂性的价值

---

## 一、什么是代理？

"Agent" 这个词有多种定义方式：

| 用户定义类型 | 描述 |
|------------|------|
| 完全自主系统 | 独立运行较长时间，使用各种工具完成复杂任务 |
| 预定流程实现 | 遵循预定工作流的更规范实现 |

Anthropic 将这些变体统一归类为 **代理性系统（Agentic Systems）**，但在架构上做出了重要区分：

### 1.1 工作流（Workflows）

- **定义**：LLM 和工具通过预定义的代码路径进行编排的系统
- **特点**：可预测、一致性高、路径固定
- **适用场景**：任务可明确定义、流程可预判的情况

### 1.2 代理（Agents）

- **定义**：LLM 动态指导自身流程和工具使用，保持对完成任务方式的控制的系统
- **特点**：灵活、自主决策、路径动态
- **适用场景**：需要灵活性和模型驱动决策的大规模场景

---

## 二、何时（以及何时不）使用代理

### 2.1 设计原则

> **"寻找尽可能简单的解决方案，仅在需要时增加复杂性"**

这意味着：**可能根本不需要构建代理性系统**。

### 2.2 权衡分析

| 维度 | 简单方案 | 代理性系统 |
|------|---------|-----------|
| **延迟** | 低 | 高（多步骤调用） |
| **成本** | 低 | 高（更多 API 调用） |
| **任务性能** | 基础 | 更高 |
| **可预测性** | 高 | 较低 |
| **灵活性** | 低 | 高 |

### 2.3 使用决策矩阵

| 场景 | 推荐方案 | 理由 |
|------|---------|------|
| 优化单个 LLM 调用 | 检索 + 上下文示例 | 通常足够 |
| 明确定义的任务 | 工作流 | 可预测性和一致性 |
| 需要大规模灵活性 | 代理 | 模型驱动的决策能力 |

---

## 三、框架的使用时机和方法

### 3.1 主流框架

| 框架 | 类型 | 特点 |
|------|------|------|
| Claude Agent SDK | SDK | Anthropic 官方代理开发工具包 |
| AWS Strands Agents SDK | SDK | AWS 的代理开发工具包 |
| Rivet | GUI 工具 | 拖放式 LLM 工作流构建器 |
| Vellum | GUI 工具 | 复杂工作流构建和测试工具 |

### 3.2 框架的优势

- 简化标准底层任务：
  - 调用 LLM
  - 定义和解析工具
  - 链式调用

### 3.3 框架的风险

| 风险 | 描述 | 后果 |
|------|------|------|
| 额外抽象层 | 掩盖底层提示和响应 | 难以调试 |
| 复杂性陷阱 | 诱惑添加不必要的复杂功能 | 简单方案即可满足需求 |

### 3.4 最佳实践

1. **直接使用 LLM API 作为起点**
   - 许多模式可以在几行代码中实现
   - 更透明的调试体验

2. **如果使用框架，要理解底层代码**
   - 对"幕后"运作的错误假设是客户错误的常见来源

3. **参考官方实现**
   - [Claude Cookbook - 代理模式](https://platform.claude.com/cookbook/patterns-agents-basic-workflows)

---

## 四、构建块、工作流和代理

以下是在生产环境中观察到的常见模式，按复杂性递增的顺序呈现：

### 4.1 基础构建块：增强型 LLM

**定义**：通过检索、工具和记忆等增强功能提升的 LLM。

**能力**：
- 主动使用这些功能
- 生成自己的搜索查询
- 选择适当的工具
- 确定保留哪些信息

**实现重点**：
1. 针对特定用例定制这些功能
2. 为 LLM 提供易于使用、文档完善的接口

**实现途径**：模型上下文协议（Model Context Protocol, MCP）
- 允许开发者通过简单的客户端实现与不断增长的第三方工具生态系统集成

---

### 4.2 工作流 1：提示链（Prompt Chaining）

**定义**：将任务分解为一系列步骤，每个 LLM 调用处理前一个调用的输出。

```
[输入] → [LLM 1] → [检查点] → [LLM 2] → [检查点] → [LLM 3] → [输出]
```

**适用场景**：
- 任务可以轻松、清晰地分解为固定的子任务
- 主要目标是用延迟换取更高准确性（使每个 LLM 调用成为更简单的任务）

**使用示例**：

| 示例 | 工作流描述 |
|------|-----------|
| 营销文案 | 生成营销文案 → 翻译成不同语言 |
| 文档写作 | 编写文档大纲 → 检查是否满足标准 → 基于大纲编写文档 |

**优势**：
- 每个步骤专注单一任务
- 中间可插入程序化检查（"gate"）
- 错误可以早期发现和纠正

---

### 4.3 工作流 2：路由（Routing）

**定义**：对输入进行分类并将其引导到专门的后续任务。

```
[输入] → [分类器] → [分支 A] / [分支 B] / [分支 C]
```

**适用场景**：
- 复杂任务，有明显的不同类别，分别处理效果更好
- 分类可以准确处理（通过 LLM 或传统分类模型/算法）

**使用示例**：

| 示例 | 路由策略 |
|------|---------|
| 客户服务查询 | 一般问题 → 退款请求 → 技术支持（各自不同流程） |
| 成本优化 | 简单问题 → Claude Haiku 4.5（低成本）<br>困难问题 → Claude Sonnet 4.5（高性能） |

**核心价值**：关注点分离
- 优化一种输入类型不会损害其他输入类型的性能
- 可以为每类任务设计专门的提示词

---

### 4.4 工作流 3：并行化（Parallelization）

**定义**：LLM 同时处理同一任务，并以编程方式聚合输出。

**两种关键变体**：

#### 变体 A：分节（Sectioning）
将任务分解为独立运行的并行子任务。

#### 变体 B：投票（Voting）
多次运行同一任务以获得多样化输出。

```
[输入] ──┬→ [LLM 实例 1] ─┐
          ├→ [LLM 实例 2] ─┼→ [聚合] → [输出]
          └→ [LLM 实例 3] ─┘
```

**适用场景**：
- 分割的子任务可以并行化以提高速度
- 需要多重视角或尝试以获得更高置信度的结果
- 复杂任务有多个考虑因素，LLM 在每个因素由单独调用处理时表现更好

**使用示例**：

| 类型 | 示例 |
|------|------|
| **分节** | 守护措施：一个模型处理用户查询，另一个筛查不当内容（优于同一 LLM 处理两者） |
| **分节** | 自动评估：每个 LLM 调用评估模型性能的不同方面 |
| **投票** | 代码安全审查：多个提示审查代码，发现问题则标记 |
| **投票** | 内容适当性评估：多个提示评估不同方面，平衡误报和漏报 |

---

### 4.5 工作流 4：编排器-工作器（Orchestrator-Workers）

**定义**：中央 LLM 动态分解任务，委派给工作器 LLM，并综合其结果。

```
        [任务输入]
            ↓
      [编排器 LLM]
    ↙       ↓       ↘
[工作器 1] [工作器 2] [工作器 3]
    ↘       ↓       ↙
      [结果综合]
            ↓
        [最终输出]
```

**与并行化的关键区别**：
- **并行化**：子任务预定义、固定
- **编排器-工作器**：子任务由编排器根据具体输入动态确定

**适用场景**：
- 复杂任务，无法预测所需的子任务
- 子任务的性质取决于具体输入

**使用示例**：

| 示例 | 描述 |
|------|------|
| 编码产品 | 每次对多个文件进行复杂更改（需更改的文件数量和每个文件的更改性质取决于任务） |
| 搜索任务 | 从多个来源收集和分析信息以查找可能的相关信息 |

**核心优势**：灵活性
- 可适应不同复杂度的任务
- 编排器可以根据需要创建任意数量的工作器

---

### 4.6 工作流 5：评估器-优化器（Evaluator-Optimizer）

**定义**：一个 LLM 调用生成响应，另一个在循环中提供评估和反馈。

```
      [初始草稿]
          ↓
    [生成器 LLM]
          ↓
    [输出评估]
          ↓
    [评估器 LLM] ←──┐
          ↓         │
    [反馈循环] ──────┘
          ↓
    [最终优化版本]
```

**适用场景判断标准**：
1. ✅ 有明确的评估标准
2. ✅ 迭代改进提供可衡量的价值
3. ✅ 人类可以明确表达反馈时，LLM 响应有明显改进
4. ✅ LLM 可以提供此类反馈

**类比**：类似于人类作家撰写精炼文档时经历的迭代写作过程

**使用示例**：

| 示例 | 工作流描述 |
|------|-----------|
| 文学翻译 | 译者 LLM 可能无法初始捕捉细微差别，但评估器 LLM 可以提供有用的批评 |
| 复杂搜索任务 | 需要多轮搜索和分析以收集全面信息，评估器决定是否需要进一步搜索 |

**核心优势**：
- 通过反馈循环持续改进输出质量
- 适用于需要精细调整的任务

---

### 4.7 代理（Agents）

**定义**：LLM 根据环境反馈在循环中使用工具，自主规划和操作的系统。

**前提条件**（随着 LLM 成熟而具备的能力）：
- 理解复杂输入
- 进行推理和规划
- 可靠地使用工具
- 从错误中恢复

**工作流程**：

```
[用户命令/对话]
      ↓
  [任务澄清]
      ↓
   [规划阶段]
      ↓
  [自主执行]
      ↓
[环境反馈获取]
      ↓
[检查点/人工反馈]
      ↓
  [继续或终止]
```

**关键特征**：
1. **启动方式**：通过人类用户的命令或交互式讨论开始工作
2. **规划能力**：任务清晰后，独立规划和操作
3. **人工介入**：可能返回人类寻求更多信息或判断
4. **环境交互**：每一步从环境获取"真值"（工具调用结果或代码执行）以评估进度
5. **控制机制**：可在检查点暂停等待人工反馈，或在遇到阻塞时暂停
6. **终止条件**：完成任务时终止，或包含停止条件（如最大迭代次数）以保持控制

**适用场景**：
- 开放式问题
- 难以或无法预测所需步骤数量
- 无法硬编码固定路径
- LLM 可能运行多个轮次
- 对其决策能力有一定程度的信任
- 受信任环境中的规模化任务

**风险与注意事项**：

| 风险 | 缓解措施 |
|------|---------|
| 更高的成本 | 监控使用量，设置预算上限 |
| 复合错误风险 | 在沙盒环境中进行广泛测试 |
| 不可预测行为 | 实施适当的防护措施 |

**实现特点**：
- 可以处理复杂的任务，但实现通常很直接
- 本质上只是 LLM 基于环境反馈在循环中使用工具
- 关键：清晰和深思熟虑地设计工具集及其文档

**官方实现示例**：

| 示例 | 描述 |
|------|------|
| 编码代理 | 解决 SWE-bench 任务，涉及基于任务描述编辑多个文件 |
| "计算机使用"参考实现 | Claude 使用计算机完成任务 |

**编码代理的高层流程**：

```
[任务描述]
    ↓
[文件分析]
    ↓
[变更规划]
    ↓
[分步执行]
    ↓
[测试验证]
    ↓
[错误恢复]
    ↓
[完成任务]
```

---

## 五、组合和自定义模式

### 5.1 设计哲学

> **这些构建块不是规定性的。它们是开发者可以塑造和组合以适应不同用例的常见模式。**

### 5.2 成功关键

与任何 LLM 功能一样，成功的关键是：
1. **测量性能**
2. **迭代实施**

### 5.3 复杂性添加原则

> **仅在能证明可以改善结果时才考虑增加复杂性**

重复强调这一点，因为：
- 过度设计是常见陷阱
- 简单方案往往已经足够
- 复杂性带来维护成本

---

## 六、核心原则总结

### 6.1 成功定义

> **LLM 领域的成功不在于构建最复杂的系统，而在于为您的需求构建正确的系统。**

### 6.2 实施路径

```
[简单提示词]
      ↓
[通过全面评估优化]
      ↓
[更简单方案不足时添加多步骤代理性系统]
```

### 6.3 三大核心原则

| 原则 | 描述 | 实践方法 |
|------|------|---------|
| **简洁性** | 保持代理设计的简洁性 | 避免不必要的复杂性和抽象层 |
| **透明度** | 明确显示代理的规划步骤 | 记录决策过程，可视化执行流程 |
| **接口质量** | 通过彻底的工具文档和测试来精心设计代理-计算机接口（ACI） | 将 ACI 视为与 HCI 同等重要 |

### 6.4 框架使用策略

```
[开发阶段] → 使用框架快速启动
      ↓
[生产阶段] → 减少抽象层，使用基本组件构建
```

**核心建议**：
- 框架可以帮助快速入门
- 但进入生产环境时，不要犹豫减少抽象层
- 使用基本组件以获得更好的控制和透明度

### 6.5 目标成果

通过遵循这些原则，可以创建既强大又可靠的代理，并且：
- ✅ 可维护
- ✅ 受用户信任
- ✅ 易于调试

---

## 七、附录 1：实践中的代理

Anthropic 与客户的合作揭示了两个特别有前景的 AI 代理应用，这些应用展示了上述模式的实用价值。

### 7.1 A. 客户支持

**为什么客户支持是代理的自然契合点**：

| 特性 | 说明 |
|------|------|
| **对话流程** | 支持交互自然遵循对话流程 |
| **外部访问** | 需要访问外部信息和操作 |
| **工具集成** | 可集成工具以提取客户数据、订单历史和知识库文章 |
| **程序化操作** | 发放退款或更新工单等操作可通过编程处理 |
| **成功衡量** | 可通过用户定义的解决方案清晰衡量成功 |

**业务模式创新**：
- 多家公司通过**基于使用量的定价模式**展示了这种方法的有效性
- 仅对成功的解决方案收费，显示对其代理效果的信心

**价值创造**：
- 自动化常见查询，降低人工成本
- 24/7 可用性
- 一致的服务质量
- 可扩展性

---

### 7.2 B. 编码代理

**为什么软件开发空间对 LLM 功能表现出显著潜力**：

| 能力演进 | 说明 |
|---------|------|
| 代码补全 | 自动完成代码片段 |
| 问题解决 | 从补全发展到自主解决问题 |
| 代理化 | 代理特别有效 |

**代理在编码中的优势**：

| 优势 | 说明 |
|------|------|
| **可验证性** | 代码解决方案可通过自动化测试验证 |
| **迭代改进** | 代理可以使用测试结果作为反馈来迭代解决方案 |
| **定义明确** | 问题空间定义明确且结构化 |
| **客观测量** | 输出质量可客观测量 |

**Anthropic 的实现成果**：
- 代理现在可以仅根据 PR 描述解决 [SWE-bench Verified](https://www.anthropic.com/research/swe-bench-sonnet) 基准测试中的真实 GitHub 问题

**局限性**：
- 虽然自动化测试有助于验证功能
- **人工审查仍然至关重要**，确保解决方案符合更广泛的系统要求

---

## 八、附录 2：工具的提示工程

### 8.1 工具的重要性

无论构建哪种代理性系统，**工具都可能是代理的重要组成部分**。

**工具的定义与作用**：
- 通过在 API 中指定其确切结构和定义，使 Claude 能够与外部服务和 API 交互
- 当 Claude 计划调用工具时，会在 API 响应中包含工具使用块

**核心观点**：
> **工具定义和规范应与整体提示词一样受到同样程度的提示工程关注。**

---

### 8.2 格式选择的考量

**问题**：通常有几种方式可以指定相同的操作。

| 操作 | 格式选项 |
|------|---------|
| 文件编辑 | 编写 diff 或重写整个文件 |
| 结构化输出 | 在 markdown 中返回代码或在 JSON 中返回 |

**关键洞察**：
- 在软件工程中，这些差异是表面的，可以无损地从一种转换为另一种
- 但对于 LLM，**某些格式比其他格式难写得多**

**格式难度对比**：

| 格式 | 挑战 |
|------|------|
| **Diff** | 需要在编写新代码之前知道块头中更改的行数 |
| **JSON 中的代码** | 需要额外的换行符和引号转义 |
| **Markdown 中的代码** | 更自然，模型训练数据中更常见 |

---

### 8.3 工具格式选择建议

1. **给模型足够的"思考"令牌**，在它把自己写入死角之前
2. **保持格式接近模型在互联网文本中自然看到的内容**
3. **确保没有格式"开销"**，例如：
   - 必须准确计算数千行代码
   - 对其编写的任何代码进行字符串转义

---

### 8.4 代理-计算机接口（ACI）设计原则

**经验法则**：
> **思考一下人机界面（HCI）投入多少精力，计划为创建良好的代理-计算机接口（ACI）投入同样多的精力。**

### 8.5 ACI 设计实践建议

| 建议 | 说明 |
|------|------|
| **站在模型的角度** | 根据描述和参数，如何使用这个工具是否明显？如果是，那么对模型来说可能也是如此 |
| **完善工具定义** | 包括示例用法、边缘情况、输入格式要求，以及与其他工具的清晰边界 |
| **优化参数** | 如何更改参数名称或描述使事情更明显？就像为团队初级开发人员编写出色的文档字符串 |
| **测试使用情况** | 在工作台中运行许多示例输入，查看模型犯什么错误，然后迭代 |
| **Poka-yoke（防错）** | 更改参数，使其更难犯错 |

**特别强调**：
- 当使用许多相似工具时，参数清晰度尤为重要

---

### 8.6 实战案例：SWE-bench 代理

**经验分享**：
在构建 [SWE-bench](https://www.anthropic.com/research/swe-bench-sonnet) 代理时，实际上**花费了更多时间优化工具而不是整体提示词**。

**具体问题与解决方案**：

| 问题 | 解决方案 |
|------|---------|
| 模型在移出根目录后使用相对文件路径时出错 | 更改工具以始终要求绝对文件路径 |
| 结果 | 模型完美地使用了这种方法 |

**启示**：
- 工具设计与优化的重要性不亚于提示词工程
- 细微的工具设计改变可以显著影响模型性能

---

## 九、关键要点总结

### 9.1 架构选择指南

```
任务明确、路径可预测？ ──是──→ [工作流]
        │
        否
        ↓
需要灵活决策？ ──是──→ [代理]
        │
        否
        ↓
[优化单个 LLM 调用]
```

### 9.2 工作流选择指南

| 工作流类型 | 核心特征 | 适用场景 |
|-----------|---------|---------|
| **提示链** | 顺序分解 | 任务可清晰分解为固定子任务 |
| **路由** | 分类分发 | 有明显不同类别，需要专门处理 |
| **并行化** | 同步执行 | 可并行加速或多视角验证 |
| **编排器-工作器** | 动态分解 | 子任务数量和类型不可预测 |
| **评估器-优化器** | 反馈循环 | 有明确评估标准，迭代改进有价值 |

### 9.3 代理评估清单

在实施代理前，确认：

- [ ] 任务是否无法预测步骤数量？
- [ ] 是否需要模型驱动的动态决策？
- [ ] 是否有足够的信任让模型自主运行？
- [ ] 是否有适当的防护措施和沙盒环境？
- [ ] 工具集是否经过精心设计和测试？
- [ ] 是否有停止条件和人工介入机制？

### 9.4 工具设计检查清单

- [ ] 工具定义是否包含示例用法？
- [ ] 是否清楚说明了边缘情况？
- [ ] 输入格式要求是否明确？
- [ ] 与其他工具的边界是否清晰？
- [ ] 是否经过多轮测试验证？
- [ ] 参数名称和描述是否足够直观？
- [ ] 是否应用了防错（Poka-yoke）设计？

---

## 十、致谢

**作者**：Erik Schluntz 和 Barry Zhang

**基础**：
- Anthropic 构建代理的经验
- 客户分享的有价值见解

---

## 结论

构建有效的 AI 代理不在于使用最复杂的框架或最先进的技术，而在于：

1. **从简单开始**，验证需求后再增加复杂性
2. **理解架构差异**，正确选择工作流或代理
3. **重视工具设计**，将 ACI 视为与 HCI 同等重要
4. **测量驱动迭代**，通过数据证明每个复杂化的价值
5. **保持透明简洁**，让系统可维护、可调试、可信任

最终目标是构建**正确**的系统，而不是最复杂的系统。

---

*本文档由 QPSCode 基于 Anthropic 原文深度分析生成*
