# AI代理的有效上下文工程 - 深度分析

> 原文来源：[Effective context engineering for AI agents](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents)
> 发布日期：2025年9月29日
> 作者：Anthropic 应用 AI 团队

---

## 目录

1. [引言：从提示词工程到上下文工程](#1-引言从提示词工程到上下文工程)
2. [上下文工程 vs 提示词工程](#2-上下文工程-vs-提示词工程)
3. [为什么上下文工程至关重要](#3-为什么上下文工程至关重要)
4. [有效上下文的构成要素](#4-有效上下文的构成要素)
5. [上下文检索与代理式搜索](#5-上下文检索与代理式搜索)
6. [长周期任务的上下文工程](#6-长周期任务的上下文工程)
7. [核心结论与最佳实践](#7-核心结论与最佳实践)

---

## 1. 引言：从提示词工程到上下文工程

### 1.1 行业演进趋势

经过几年提示词工程（Prompt Engineering）成为应用AI关注焦点之后，一个新术语开始占据主导地位：**上下文工程（Context Engineering）**。

构建基于语言模型的应用正在从"找到提示词的正确词语和短语"转向回答一个更广泛的问题：

> **"什么样的上下文配置最有可能生成我们模型期望的行为？"**

### 1.2 核心概念定义

| 术语 | 定义 |
|------|------|
| **上下文（Context）** | 从大语言模型（LLM）采样时包含的令牌（token）集合 |
| **工程（Engineering）** | 优化这些令牌的效用，以对抗 LLM 的固有约束，从而持续实现期望的结果 |
| **上下文工程** | 在 LLM 推理过程中精心策划和维护最优令牌（信息）集合的策略集合 |
| **在上下文中思考** | 考虑 LLM 在任何给定时间可用的整体状态，以及该状态可能产生的潜在行为 |

### 1.3 核心洞察

有效驾驭 LLM 通常需要**"在上下文中思考"**——即考虑 LLM 在任何给定时间可用的整体状态，以及该状态可能产生的潜在行为。

---

## 2. 上下文工程 vs 提示词工程

### 2.1 概念对比

| 维度 | 提示词工程 | 上下文工程 |
|------|-----------|-----------|
| **关注点** | 如何编写和组织 LLM 指令以获得最佳结果 | 如何策划和维护 LLM 推理期间的最优令牌集合 |
| **范围** | 主要关注系统提示词的编写 | 包括所有可能进入上下文的信息（系统指令、工具、MCP、外部数据、消息历史等） |
| **工作方式** | 离散任务（编写一个提示词） | 迭代过程（每次决定向模型传递什么时都要进行策划） |
| **发展阶段** | 早期 LLM 工程的核心 | 面向更强大代理的自然演进 |

### 2.2 提示词工程的局限性

在 LLM 工程的早期阶段，提示词编写是 AI 工程工作的最大组成部分，因为大多数超越日常聊天交互的用例都需要针对一次性分类或文本生成任务进行优化的提示词。

**局限性体现：**
- 主要专注于如何编写有效的提示词，特别是系统提示词
- 难以处理多轮推理和更长时间跨度的代理任务
- 无法有效管理整个上下文状态

### 2.3 上下文工程的必要性

随着我们走向工程化更强大的代理——这些代理在多轮推理和更长的时间范围内运行，我们需要管理整个上下文状态的策略。

**上下文工程需要管理的内容：**
- 系统指令
- 工具定义
- 模型上下文协议（MCP）
- 外部数据
- 消息历史
- 其他可能进入上下文的信息

### 2.4 上下文工程的艺术与科学

在一个循环中运行的代理会产生越来越多的数据，这些数据*可能*与下一轮推理相关，而这些信息必须进行循环提炼。

上下文工程是从这个不断演变的可能信息宇宙中，策划出有限上下文窗口内容的**艺术和科学**。

---

## 3. 为什么上下文工程至关重要

### 3.1 上下文衰减（Context Rot）现象

研究表明，LLM 和人类一样，在达到某一点后会失去焦点或产生困惑。针对"大海捞针"式基准测试的研究揭示了**上下文衰减**的概念：

> **随着上下文窗口中令牌数量的增加，模型准确回忆该上下文中的信息的能力会下降。**

### 3.2 注意力预算理论

像人类具有有限的工作记忆容量一样，LLM 也有一个"注意力预算"，用于解析大量上下文。

**关键机制：**
- 每引入一个新令牌，都会消耗一定量的预算
- 需要仔细策划可提供给 LLM 的令牌
- 上下文必须被视为一种边际收益递减的有限资源

### 3.3 架构约束

注意力稀缺源于 LLM 的架构约束：

| 约束因素 | 说明 |
|---------|------|
| **Transformer 架构** | 每个令牌都可以关注整个上下文中的每个其他令牌 |
| **n² 复杂度** | n 个令牌产生 n² 个成对关系 |
| **注意力模式** | 模型从训练数据分布中发展注意力模式，其中较短序列通常比较长序列更常见 |
| **专门参数** | 对于上下文范围的依赖关系，模型的经验较少，专门参数也较少 |

### 3.4 性能梯度而非悬崖

这些因素创造了性能梯度而非硬性悬崖：
- 模型在较长上下文中仍然高度有能力
- 但在信息检索和远程推理方面可能显示降低的精度
- 技术如位置编码插值允许模型通过将其适应到原始训练的较小上下文来处理更长的序列

### 3.5 现实意义

这些现实意味着深思熟虑的上下文工程对于构建有能力的代理是必不可少的。

---

## 4. 有效上下文的构成要素

### 4.1 核心指导原则

鉴于 LLM 受限于有限的注意力预算，**好的上下文工程意味着找到**：

> **尽可能最小的高信号令牌集合，以最大化某种期望结果的可能性**

### 4.2 系统提示词（System Prompts）

#### 4.2.1 基本要求

系统提示词应该：
- **极其清晰**
- 使用简单、直接的语言
- 在代理的**正确高度**呈现思想

#### 4.2.2 "正确高度"概念

正确高度是两个常见失败模式之间的金发姑娘区域：

```
┌─────────────────────────────────────────────────────────────┐
│              过度详细（脆弱的硬编码逻辑）                      │
│  ─────────────────────────────────────────────────────────   │
│                    ✅ 最优高度（推荐）                         │
│  ─────────────────────────────────────────────────────────   │
│              过于模糊（缺乏具体指导）                          │
└─────────────────────────────────────────────────────────────┘
```

| 失败模式 | 特征 | 问题 |
|---------|------|------|
| **过度详细** | 在提示词中硬编码复杂的、脆弱的逻辑以引发精确的代理行为 | 创造脆弱性，随时间增加维护复杂性 |
| **过于模糊** | 提供模糊的、高层次的指导 | 无法给 LLM 提供期望输出的具体信号，或错误地假设共享上下文 |
| **最优高度** | 足够具体以有效指导行为，但也足够灵活以提供强启发式 | 平衡具体性和灵活性 |

#### 4.2.3 结构化建议

- **组织方式**：将提示词组织成不同的部分
  - `<background_information>`
  - `<instructions>`
  - `## Tool guidance`
  - `## Output description`

- **分隔技术**：使用 XML 标记或 Markdown 标题来界定这些部分
  - 注意：提示词的确切格式可能正变得不那么重要，因为模型变得更强大

#### 4.2.4 最小化策略

无论您决定如何构建系统提示词，您都应该努力实现**完全概述期望行为的最小信息集**。

> **最小并不一定意味着短**——您仍然需要预先给代理足够的信息以确保它遵守期望的行为。

**建议方法：**
1. 从使用最佳可用模型测试最小提示词开始
2. 查看它在您的任务上的表现
3. 根据初始测试中发现的失败模式添加清晰的指令和示例以提高性能

### 4.3 工具（Tools）

#### 4.3.1 工具的作用

工具允许代理与其环境操作并在工作时引入新的、额外的上下文。

因为工具定义了代理与信息/操作空间之间的契约，所以工具促进效率**极其重要**：
- 通过返回令牌效率高的信息
- 通过鼓励高效的代理行为

#### 4.3.2 工具设计原则

根据《Writing tools for AI agents – with AI agents》，工具应该：

| 原则 | 说明 |
|------|------|
| **被 LLM 理解** | 工具应易于 LLM 理解 |
| **功能最小重叠** | 类似于设计良好的代码库的功能 |
| **自包含** | 每个工具应独立完成其职责 |
| **错误鲁棒** | 对错误具有鲁棒性 |
| **用途明确** | 对于其预期用途极其清晰 |
| **参数清晰** | 输入参数应该是描述性的、无歧义的，并发挥模型的固有优势 |

#### 4.3.3 常见失败模式

我们看到的最常见失败模式是**臃肿的工具集**：
- 涵盖太多功能
- 导致关于使用哪个工具的歧义决策点

**判断标准：**
> 如果人类工程师不能确定地说在给定情况下应该使用哪个工具，那么就不应该指望 AI 代理做得更好。

**最佳实践：**
- 为代理策划最小可行工具集
- 这也会导致在长时间交互中更可靠的维护和上下文修剪

### 4.4 示例（Examples）

#### 4.4.1 少样本提示

提供示例，也称为少样本提示，是一个众所周知的最佳实践，我们继续强烈建议。

#### 4.4.2 避免边缘情况列表

我们**不推荐**将边缘情况列表塞入提示词，试图陈述 LLM 应该为特定任务遵循的每条可能规则。

#### 4.4.3 推荐做法

相反，我们建议策划一组**多样化、规范的示例**，这些示例有效地描绘代理的期望行为。

> 对于 LLM 来说，示例是"值一千字的图片"。

### 4.5 上下文各组件的总体指导

| 组件 | 策略 |
|------|------|
| 系统提示词 | 极其清晰、简单直接、正确高度、最小信息集 |
| 工具 | 最小可行集合、功能明确、参数清晰、错误鲁棒 |
| 示例 | 多样化、规范、有效描绘期望行为 |
| 消息历史 | 定期压缩、清理无关信息 |
| 其他数据 | 高信号、低噪声、及时性 |

**总体原则：**深思熟虑并保持您的上下文信息丰富但紧凑。

---

## 5. 上下文检索与代理式搜索

### 5.1 工作流 vs 代理

在《Building effective AI agents》中，我们强调了基于 LLM 的工作流与代理之间的差异。

**代理的简单定义：**
> LLM 在循环中自主使用工具。

自从我们发表那篇文章以来，我们倾向于这个简单的定义。随着底层模型变得更有能力，代理的自主性水平可以扩展：
- 更智能的模型允许代理独立导航细致的问题空间
- 能够从错误中恢复

### 5.2 上下文设计范式转变

我们现在看到工程师思考如何为代理设计上下文的方式发生了转变。

| 传统方法 | 代理方法 |
|---------|---------|
| 推理前基于嵌入的检索 | "即时"上下文策略 |
| 预处理所有相关数据 | 维护轻量级标识符，运行时动态加载 |
| 静态索引 | 自主导航和渐进式发现 |

今天，许多 AI 原生应用程序采用某种形式的**推理前基于嵌入的检索**来浮现重要的上下文供代理推理。随着领域转向更多代理方法，我们越来越多地看到团队用"即时"上下文策略增强这些检索系统。

### 5.3 "即时"（Just-in-Time）方法

#### 5.3.1 基本机制

与其预先处理所有相关数据，采用"即时"方法构建的代理：
- 维护轻量级标识符（文件路径、存储查询、Web 链接等）
- 使用这些引用在运行时使用工具动态地将数据加载到上下文中

#### 5.3.2 Claude Code 实例

Anthropic 的代理编码解决方案 Claude Code 使用这种方法对大型数据库执行复杂的数据分析：

| 能力 | 实现方式 |
|------|---------|
| 编写定向查询 | 模型编写特定的 SQL 查询 |
| 存储结果 | 将查询结果暂存 |
| 分析大数据 | 使用 head 和 tail 等 Bash 命令分析大量数据 |
| 避免全量加载 | 无需将完整数据对象加载到上下文中 |

#### 5.3.3 认知类比

这种方法镜像人类认知：
- 我们通常不记忆整个信息语料库
- 而是引入外部组织和索引系统（如文件系统、收件箱、书签）来按需检索相关信息

### 5.4 引用的元数据价值

除了存储效率，这些引用的元数据提供了一种机制来有效地细化行为，无论是明确提供还是直观的。

**元数据信号示例：**

| 元数据类型 | 提供的信息 |
|-----------|-----------|
| 文件路径 | `tests/test_utils.py` vs `src/core_logic/test_utils.py` 暗示不同的目的 |
| 文件夹层次 | 项目结构和组织模式 |
| 命名约定 | 功能和目的的暗示 |
| 时间戳 | 相关性代理 |

> 对于在文件系统中操作的代理，位于 `tests` 文件夹中名为 `test_utils.py` 的文件意味着与位于 `src/core_logic/` 中的同名文件不同的目的。

### 5.5 渐进式披露

让代理自主导航和检索数据也使**渐进式披露**成为可能——换句话说，允许代理通过探索增量地发现相关上下文。

**渐进式披露的特点：**
- 每次交互都会产生告知下一个决策的上下文
- 文件大小暗示复杂性
- 命名约定提示目的
- 时间戳可以是相关性的代理

**代理可以逐层组装理解：**
- 在工作记忆中仅保持必要的内容
- 利用笔记策略进行额外的持久化
- 保持对相关子集的关注，而不是淹没在详尽但可能无关的信息中

### 5.6 权衡与考虑

#### 5.6.1 权衡

| 方面 | 推理前检索 | 即时检索 |
|------|-----------|---------|
| **速度** | 快（预计算） | 慢（运行时探索） |
| **新鲜度** | 可能过时 | 实时 |
| **上下文效率** | 可能加载无关信息 | 按需加载 |
| **工程复杂度** | 低（静态索引） | 高（需要导航工具） |

#### 5.6.2 挑战

运行时探索比检索预计算数据要慢。不仅如此，还需要有主见和深思熟虑的工程来确保 LLM 拥有有效导航其信息景观的正确工具和启发式方法。

**如果没有适当的指导，代理可能会：**
- 误用工具，浪费上下文
- 追逐死胡同
- 未能识别关键信息

### 5.7 混合策略

在某些设置中，最有效的代理可能采用混合策略：
- 预先检索一些数据以获得速度
- 根据需要进行进一步的自主探索

#### 5.7.1 决策边界

"正确"自主性水平的决策边界取决于任务。

**Claude Code 示例：**
- **预先**：CLAUDE.md 文件被朴素地放入上下文
- **即时**：glob 和 grep 等原语允许它导航其环境并即时检索文件
- **优势**：有效地绕过过时索引和复杂语法树的问题

#### 5.7.2 适用场景

混合策略可能更适合**内容不太动态的上下文**，例如：
- 法律工作
- 金融工作

### 5.8 未来趋势

随着模型能力的提高，代理设计将趋向于让智能模型智能地行动，人类策划越来越少。

> **"做最简单的有效事情"很可能会继续成为在 Claude 上构建代理的团队的最佳建议。**

---

## 6. 长周期任务的上下文工程

### 6.1 长周期任务的挑战

长周期任务要求代理在令牌计数超过 LLM 上下文窗口的动作序列中保持一致性、上下文和目标导向行为。

**典型场景：**
- 大型代码库迁移
- 综合研究项目
- 持续数十分钟到数小时的工作

### 6.2 简单方案的问题

等待更大的上下文窗口似乎是一个明显的策略。但很可能在可预见的未来，所有大小的上下文窗口都将受到上下文污染和信息相关性问题的困扰——至少在需要最强代理性能的情况下。

### 6.3 核心解决方案

为了使代理能够在扩展的时间范围内有效工作，我们开发了几种技术来直接解决这些上下文污染约束：

| 技术 | 目的 | 适用场景 |
|------|------|---------|
| **压缩** | 减少上下文大小，保留关键信息 | 需要大量对话的任务 |
| **结构化笔记** | 在上下文外持久化记忆 | 迭代开发、里程碑跟踪 |
| **多代理架构** | 分离关注点，并行处理 | 复杂研究、大型项目 |

### 6.4 压缩（Compaction）

#### 6.4.1 定义

压缩是将接近上下文窗口限制的对话总结其内容，并用总结重新初始化新的上下文窗口的实践。

#### 6.4.2 作用

压缩通常作为上下文工程中推动更好的长期一致性的第一个杠杆。

**核心能力：**
- 以高保真度提取上下文窗口的内容
- 使代理能够以最小的性能下降继续

#### 6.4.3 Claude Code 实现

在 Claude Code 中，我们通过将消息历史传递给模型以总结和压缩最关键的细节来实现这一点。

**保留的内容：**
- 架构决策
- 未解决的错误
- 实现细节

**丢弃的内容：**
- 冗余的工具输出
- 冗余的消息

**结果：**
- 代理可以使用这个压缩的上下文加上最近访问的五个文件继续
- 用户获得连续性，无需担心上下文窗口限制

#### 6.4.4 压缩的艺术

压缩的艺术在于选择保留什么与丢弃什么。

**风险：**
- 过度激进的压缩可能导致丢失微妙的但关键的上下文
- 这些上下文的重要性可能只在后来变得明显

#### 6.4.5 实施建议

对于实现压缩系统的工程师，我们建议仔细调整您在复杂代理跟踪上的提示词。

**迭代方法：**
1. 首先最大化召回率，确保您的压缩提示词捕获跟踪中的每一条相关信息
2. 然后迭代以提高精度，消除多余内容

#### 6.4.6 工具结果清理

最安全的轻量级压缩形式之一是**工具结果清理**。

> 一旦工具在消息历史深处被调用，为什么代理需要再次看到原始结果？

这种技术最近已作为 Claude Developer Platform 上的一项功能推出。

### 6.5 结构化笔记（Structured Note-taking）

#### 6.5.1 定义

结构化笔记或代理记忆，是一种技术，代理定期将笔记写入在上下文外持久化的记忆。这些笔记在稍后时间被拉回上下文窗口。

#### 6.5.2 优势

该策略以最小开销提供持久记忆。

**模式示例：**
- Claude Code 创建待办事项列表
- 自定义代理维护 NOTES.md 文件

**价值：**
- 允许代理在复杂任务中跟踪进度
- 维持关键的上下文和依赖关系
- 否则这些信息将在数十次工具调用中丢失

#### 6.5.3 非编码领域示例

**Claude playing Pokémon** 演示了记忆如何转变代理在非编码领域能力。

代理维护跨越数千个游戏步骤的精确计数：
- 跟踪目标，如"最后 1,234 步我在 Route 1 训练我的宝可梦"
- "皮卡丘向目标的 10 级获得了 8 级"

**自主发展：**
- 开发探索区域的地图
- 记住已解锁的关键成就
- 维持战斗策略的战略笔记
- 帮助学习哪些攻击对不同对手最有效

#### 6.5.4 跨会话一致性

上下文重置后：
- 代理读取自己的笔记
- 继续多小时的训练序列或地牢探索

**这种跨越总结步骤的一致性使能了长时间视界的策略**，当仅将所有信息保留在 LLM 的上下文窗口中时，这是不可能的。

#### 6.5.5 实现工具

作为 Sonnet 4.5 发布的一部分，我们在 Claude Developer Platform 上发布了测试版的记忆工具，使代理更容易通过基于文件的系统在上下文窗口外存储和咨询信息。

**功能：**
- 允许代理随时间建立知识库
- 跨会话维护项目状态
- 引用以前的工作而无需将所有内容保持在上下文中

### 6.6 多代理架构（Sub-agent Architectures）

#### 6.6.1 基本概念

多代理架构提供了绕过上下文限制的另一种方式。

**设计原则：**
- 不是让一个代理尝试在整个项目中维护状态
- 专门的子代理可以处理具有清晰上下文窗口的专注任务

#### 6.6.2 角色分工

| 角色 | 职责 |
|------|------|
| **主代理** | 高层计划，协调子代理 |
| **子代理** | 深度技术工作，使用工具查找相关信息 |

#### 6.6.3 工作流程

1. 主代理使用高层计划进行协调
2. 子代理执行深度技术工作或使用工具查找相关信息
3. 每个子代理可能广泛探索，使用数万或更多令牌
4. 但仅返回其工作的压缩、提炼总结（通常 1,000-2,000 令牌）

#### 6.6.4 优势

这种方法实现了清晰的**关注点分离**：
- 详细的搜索上下文保持在子代理内部隔离
- 主代理专注于综合和分析结果

#### 6.6.5 实证验证

这种模式在《How we built our multi-agent research system》中进行了讨论，在复杂研究任务上显示出比单代理系统**实质性改进**。

### 6.7 技术选择指南

| 技术 | 最适合 |
|------|--------|
| **压缩** | 需要大量来回的任务，保持对话流畅 |
| **笔记** | 具有明确里程碑的迭代开发 |
| **多代理架构** | 复杂研究和分析，并行探索带来收益 |

### 6.8 持续的挑战

即使模型继续改进，在扩展交互中保持一致性的挑战仍将仍然是构建更有效代理的核心。

---

## 7. 核心结论与最佳实践

### 7.1 范式转变

上下文工程代表了我们使用 LLM 构建方式的根本转变。

| 旧范式 | 新范式 |
|-------|-------|
| 完美的提示词 | 策划上下文配置 |
| 离散任务 | 迭代过程 |
| 一次性优化 | 持续管理 |

### 7.2 核心指导原则

随着模型变得更有能力，挑战不仅仅是制定完美的提示词——它是在每一步深思熟虑地策划进入模型有限注意力预算的信息。

**统一指导原则：**
> **找到最小的高信号令牌集合，以最大化您期望结果的可能性。**

### 7.3 技术总结

| 技术领域 | 关键策略 | 核心目标 |
|---------|---------|---------|
| **系统提示词** | 清晰、简洁、正确高度 | 最小信息集，完整行为描述 |
| **工具设计** | 最小可行集合、明确职责 | 效率和清晰的决策点 |
| **示例选择** | 多样化、规范 | 一幅图片值一千字 |
| **上下文检索** | 混合策略（预检索 + 即时检索） | 速度与新鲜度的平衡 |
| **长期任务** | 压缩、笔记、多代理 | 扩展时间范围内的一致性 |

### 7.4 演进趋势

我们概述的技术将随着模型的改进继续演变。

**观察趋势：**
- 更智能的模型需要更少的规定性工程
- 允许代理以更多自主性操作
- 但即使能力扩展，将上下文视为珍贵、有限的资源仍将仍然是构建可靠、有效代理的核心

### 7.5 实践建议

**"做最简单的有效事情"**很可能会继续成为在 Claude 上构建代理的团队的最佳建议。

### 7.6 资源链接

- [Claude Developer Platform](https://platform.claude.com/)
- [Memory and Context Management Cookbook](https://platform.claude.com/cookbook/tool-use-memory-cookbook)
- [Writing tools for AI agents](https://www.anthropic.com/engineering/writing-tools-for-agents)
- [Building effective AI agents](https://www.anthropic.com/research/building-effective-agents)
- [How we built our multi-agent research system](https://www.anthropic.com/engineering/multi-agent-research-system)
- [Model Context Protocol](https://modelcontextprotocol.io/docs/getting-started/intro)

---

## 附录：关键术语表

| 术语 | 英文 | 定义 |
|------|------|------|
| 上下文 | Context | 从 LLM 采样时包含的令牌集合 |
| 上下文工程 | Context Engineering | 策划和维护 LLM 推理期间最优令牌集合的策略 |
| 上下文衰减 | Context Rot | 随着上下文窗口中令牌数量增加，模型准确回忆信息能力下降的现象 |
| 注意力预算 | Attention Budget | LLM 解析大量上下文时可用的有限注意力资源 |
| 压缩 | Compaction | 总结接近限制的对话内容并用总结重新初始化新上下文窗口的实践 |
| 结构化笔记 | Structured Note-taking | 代理定期将笔记写入上下文外持久化记忆的技术 |
| 即时检索 | Just-in-time Retrieval | 在运行时使用工具动态将数据加载到上下文中的方法 |
| 渐进式披露 | Progressive Disclosure | 允许代理通过探索增量发现相关上下文的方法 |

---

**文档版本：** 1.0
**分析日期：** 2026年2月11日
**文档生成：** Claude Opus 4.5
