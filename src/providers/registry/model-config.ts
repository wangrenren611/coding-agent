/**
 * 模型配置存储
 *
 * 集中管理所有模型的配置信息，可从外部加载
 */

import type { ModelConfig, ModelId } from '../types';

/**
 * 模型配置表（以模型 ID 为键，不包含 apiKey 的配置）
 */
export const MODEL_DEFINITIONS: Record<ModelId, Omit<ModelConfig, 'apiKey'>> = {
    // Anthropic 系列
    'claude-opus-4.6': {
        id: 'claude-opus-4.6',
        provider: 'anthropic',
        name: 'Claude Opus 4.6',
        baseURL: '',
        endpointPath: '/chat/completions',
        envApiKey: 'ANTHROPIC_API_KEY',
        envBaseURL: 'ANTHROPIC_API_BASE',
        model: 'claude-opus-4-6',
        max_tokens: 16384,
        LLMMAX_TOKENS: 1000 * 1000,
        features: ['streaming', 'function-calling', 'vision'],
    },
    // GLM 系列
    'glm-4.7': {
        id: 'glm-4.7',
        provider: 'glm',
        name: 'GLM-4.7',
        baseURL: 'https://open.bigmodel.cn/api/paas/v4',
        endpointPath: '/chat/completions',
        envApiKey: 'GLM_API_KEY',
        envBaseURL: 'GLM_API_BASE',
        model: 'GLM-4.7',
        max_tokens: 8000,
        LLMMAX_TOKENS: 200 * 1000,
        features: ['streaming', 'function-calling', 'vision'],
    },
    // GLM 系列
    'glm-5': {
        id: 'glm-5',
        provider: 'glm',
        name: 'GLM-5',
        baseURL: 'https://open.bigmodel.cn/api/paas/v4',
        endpointPath: '/chat/completions',
        envApiKey: 'GLM_API_KEY',
        envBaseURL: 'GLM_API_BASE',
        model: 'glm-5',
        max_tokens: 8000,
        LLMMAX_TOKENS: 200 * 1000,
        features: ['streaming', 'function-calling', 'vision'],
    },
    // MiniMax 系列
    'minimax-2.5': {
        id: 'minimax-2.5',
        provider: 'minimax',
        name: 'MiniMax-2.5',
        baseURL: 'https://api.minimaxi.com/v1',
        endpointPath: '/chat/completions',
        envApiKey: 'MINIMAX_API_KEY',
        envBaseURL: 'MINIMAX_API_URL',
        model: 'MiniMax-M2.5',
        max_tokens: 8000,
        LLMMAX_TOKENS: 200 * 1000,
        features: ['streaming', 'function-calling'],
    },
    // Kimi 系列
    'kimi-k2.5': {
        id: 'kimi-k2.5',
        provider: 'kimi',
        name: 'Kimi K2.5',
        baseURL: 'https://api.kimi.com/coding/v1',
        endpointPath: '/chat/completions',
        envApiKey: 'KIMI_API_KEY',
        envBaseURL: 'KIMI_API_BASE',
        model: 'kimi-for-coding',
        max_tokens: 8000,
        LLMMAX_TOKENS: 200 * 1000,
        features: ['streaming', 'function-calling', 'reasoning'],
        temperature: 0.6,
        thinking: false,
    },
    // DeepSeek 系列
    'deepseek-chat': {
        id: 'deepseek-chat',
        provider: 'deepseek',
        name: 'DeepSeek Chat',
        baseURL: 'https://api.deepseek.com/v1',
        endpointPath: '/chat/completions',
        envApiKey: 'DEEPSEEK_API_KEY',
        envBaseURL: 'DEEPSEEK_API_BASE',
        model: 'deepseek-chat',
        max_tokens: 8000,
        LLMMAX_TOKENS: 128 * 1000,
        features: ['streaming', 'function-calling'],
    },
    // Qwen 系列
    'qwen3.5-plus': {
        id: 'qwen3.5-plus',
        provider: 'qwen',
        name: 'Qwen 3.5 Plus',
        baseURL: 'https://coding.dashscope.aliyuncs.com/v1',
        endpointPath: '/chat/completions',
        envApiKey: 'QEPSEEK_API_KEY',
        envBaseURL: 'QEPSEEK_API_BASE',
        model: 'qwen3.5-plus',
        max_tokens: 8000,
        LLMMAX_TOKENS: 1024 * 1000,
        features: ['streaming', 'function-calling'],
    },
    'qwen-kimi-k2.5': {
        id: 'qwen-kimi-k2.5',
        provider: 'qwen',
        name: 'qwen kimi k2.5',
        baseURL: 'https://coding.dashscope.aliyuncs.com/v1',
        endpointPath: '/chat/completions',
        envApiKey: 'QEPSEEK_API_KEY',
        envBaseURL: 'QEPSEEK_API_BASE',
        model: 'kimi-k2.5',
        max_tokens: 8000,
        LLMMAX_TOKENS: 200 * 1000,
        features: ['streaming', 'function-calling'],
    },
    'qwen-glm-5': {
        id: 'qwen-glm-5',
        provider: 'qwen',
        name: 'Qwen GLM 5',
        baseURL: 'https://coding.dashscope.aliyuncs.com/v1',
        endpointPath: '/chat/completions',
        envApiKey: 'QEPSEEK_API_KEY',
        envBaseURL: 'QEPSEEK_API_BASE',
        model: 'glm-5',
        max_tokens: 8000,
        LLMMAX_TOKENS: 200 * 1000,
        features: ['streaming', 'function-calling'],
    },
    'wr-claude-4.6': {
        id: 'wr-claude-4.6',
        provider: 'openai',
        name: 'Claude Opus 4.6',
        baseURL: '',
        endpointPath: '/chat/completions',
        envApiKey: 'ANTHROPIC_API_KEY',
        envBaseURL: 'ANTHROPIC_API_BASE',
        model: 'claude-opus-4-6',
        max_tokens: 16384,
        LLMMAX_TOKENS: 1000 * 1000,
        features: ['streaming', 'function-calling', 'vision'],
    },
};
