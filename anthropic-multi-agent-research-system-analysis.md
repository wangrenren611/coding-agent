# Anthropic 多智能体研究系统深度分析

> 原文标题：How we built our multi-agent research system
> 发布时间：2025年6月13日
> 作者：Jeremy Hadfield, Barry Zhang, Kenneth Lien, Florian Scholz, Jeremy Fox, Daniel Ford

---

## 目录

1. [概述](#概述)
2. [多智能体系统的优势](#多智能体系统的优势)
3. [Research 功能架构概述](#research-功能架构概述)
4. [研究智能体的提示工程与评估](#研究智能体的提示工程与评估)
5. [智能体的有效评估方法](#智能体的有效评估方法)
6. [生产可靠性与工程挑战](#生产可靠性与工程挑战)
7. [结论](#结论)
8. [附录：额外技巧](#附录额外技巧)
9. [核心洞察总结](#核心洞察总结)

---

## 概述

Anthropic 的 Research 功能使用多个 Claude 智能体更有效地探索复杂主题。本文分享了构建该系统过程中遇到的工程挑战以及学到的经验教训。

### 核心概念

**多智能体系统**：由多个智能体（LLM 在循环中自主使用工具）协同工作组成的系统。

Anthropic 的 Research 功能包含：
- 一个基于用户查询规划研究流程的**主导智能体（Lead Agent）**
- 使用工具创建并行搜索信息的**子智能体（Subagents）**

从原型到生产的过程中，多智能体系统引入了**智能体协调、评估和可靠性**方面的新挑战。

---

## 多智能体系统的优势

### 1. 研究任务的本质特征

研究工作涉及开放性问题，难以预先预测所需步骤。探索复杂主题时，无法硬编码固定路径，因为过程本质上是动态且路径依赖的。人类进行研究时，倾向于根据发现不断更新方法，追踪调查过程中出现的线索。

AI 智能体特别适合研究任务，因为：
- 需要在调查展开时转向或探索切向连接的灵活性
- 模型必须自主运行多个回合，根据中间发现决策 pursue 哪些方向
- 线性的、一次性管道无法处理这些任务

### 2. 搜索的本质是压缩

搜索的本质是压缩：从庞大的语料库中提炼见解。子智能体通过以下方式促进压缩：

| 机制 | 作用 |
|------|------|
| 并行操作 | 使用独立的上下文窗口 |
| 独立探索 | 同时探索问题的不同方面 |
| 信息聚合 | 将最重要的 token 浓缩给主导研究智能体 |
| 关注点分离 | 每个子智能体有独立的工具、提示和探索轨迹 |

这种关注点分离减少了路径依赖，实现了彻底的独立调查。

### 3. 集体智能的指数级增长

一旦智能达到一定阈值，多智能体系统成为扩展性能的重要方式。

- 过去 10 万年中，个体人类的智能力量增长有限
- 但由于**集体智能**和协调能力，人类社会在信息时代的能力呈**指数级**增长
- 即使是通用智能智能体作为个体操作时也面临限制
- 智能体群体可以完成更多工作

### 4. 性能对比数据

Anthropic 的内部评估显示，多智能体研究系统在**广度优先查询**方面表现优异：

**测试案例**：识别信息技术标准普尔 500 指数中所有公司的董事会成员

| 系统配置 | 结果 |
|---------|------|
| 单智能体 Claude Opus 4 | 失败（缓慢的顺序搜索） |
| 多智能体系统<br>（Claude Opus 4 为主 + Claude Sonnet 4 子智能体） | 成功（通过任务分解） |

**总体提升**：多智能体系统在内部研究评估中比单智能体 Claude Opus 4 高出 **90.2%**。

### 5. Token 使用与性能的关系

多智能体系统有效工作的原因主要是帮助消耗足够的 token 来解决问题。

在 **BrowseComp 评估**（测试浏览智能体定位难以找到信息的能力）中：

| 解释因子 | 方差解释度 |
|---------|-----------|
| Token 使用量 | 80% |
| 工具调用数量 | 部分解释 |
| 模型选择 | 部分解释 |
| **三者总计** | **95%** |

这验证了 Anthropic 的架构：将工作分布在具有独立上下文窗口的智能体之间，增加了并行推理的容量。

**Claude 4 模型作为效率倍增器**：
- 升级到 Claude Sonnet 4 的性能提升 > 在 Claude Sonnet 3.7 上将 token 预算翻倍
- 多智能体架构有效地为超过单智能体限制的任务扩展了 token 使用

### 6. 成本与适用场景

**成本考虑**：
- 智能体通常比聊天交互多使用约 **4×** token
- 多智能体系统比聊天多使用约 **15×** token

**经济可行性**：多智能体系统需要任务价值足够高以支付提升的性能。

**不适合的场景**：
- 需要所有智能体共享相同上下文的领域
- 智能体之间有很多依赖关系的领域
- 例如：大多数编码任务（真正可并行化的任务较少）
- LLM 智能体尚未擅长实时与其他智能体协调和委派

**最佳应用场景**：
- 涉及大量并行的有价值任务
- 信息超过单个上下文窗口
- 需要与众多复杂工具交互

---

## Research 功能架构概述

### 1. 编排器-工作器模式

Research 系统使用多智能体架构，采用**编排器-工作器（Orchestrator-Worker）模式**：

```
用户查询
   ↓
主导智能体（分析、制定策略、生成子智能体）
   ↓
子智能体并行执行（智能过滤器、搜索工具）
   ↓
主导智能体（编译最终答案）
```

**流程说明**：
1. 用户提交查询
2. 主导智能体分析查询、制定策略
3. 生成子智能体同时探索不同方面
4. 子智能体作为智能过滤器，迭代使用搜索工具收集信息
5. 将发现列表返回给主导智能体编译最终答案

### 2. 与传统 RAG 的对比

| 特性 | 传统 RAG | Anthropic 多智能体架构 |
|------|----------|----------------------|
| 检索方式 | 静态检索 | 多步动态搜索 |
| 检索策略 | 获取与输入查询最相似的块 | 动态发现相关信息 |
| 适应性 | 固定 | 适应新发现 |
| 分析能力 | 基于静态块 | 分析结果并形成高质量答案 |

### 3. 完整工作流程

```
┌─────────────────────────────────────────────────────────────────┐
│                         用户提交查询                               │
└─────────────────────────┬───────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────────────┐
│                    创建 LeadResearcher 智能体                     │
└─────────────────────────┬───────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────────────┐
│                    进入迭代研究过程                               │
│  1. 思考方法                                                     │
│  2. 将计划保存到 Memory（持久化上下文）                           │
│     └─ 原因：上下文窗口超过 200,000 token 会被截断                │
└─────────────────────────┬───────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────────────┐
│                    创建专业 Subagents                             │
│  • 每个子智能体有特定研究任务                                    │
│  • 独立执行网页搜索                                              │
│  • 使用交错思考评估工具结果                                      │
│  • 将发现返回给 LeadResearcher                                   │
└─────────────────────────┬───────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────────────┐
│                LeadResearcher 综合结果                            │
│  • 决定是否需要更多研究                                         │
│  • 如需要：创建额外子智能体或优化策略                            │
│  • 如已充分：退出研究循环                                        │
└─────────────────────────┬───────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────────────┐
│                    CitationAgent 处理                            │
│  • 处理文档和研究报告                                            │
│  • 识别具体引用位置                                              │
│  • 确保所有声明都有适当的来源归属                                  │
└─────────────────────────┬───────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────────────┐
│                    返回带引用的最终研究结果                        │
└─────────────────────────────────────────────────────────────────┘
```

### 4. Memory 机制的重要性

- **持久化关键上下文**：当上下文窗口超过 200,000 token 会被截断
- **保留研究计划**：确保在上下文限制时不丢失原始策略
- **检索机制**：子智能体可以从记忆中检索存储的上下文（如研究计划）

---

## 研究智能体的提示工程与评估

### 多智能体系统与单智能体系统的关键差异

**协调复杂度的快速增长**：
- 早期智能体的错误行为：
  - 为简单查询生成 50 个子智能体
  - 无休止地搜索不存在的来源
  - 用过多更新分散彼此注意力

由于每个智能体由提示驱动，**提示工程**是改善这些行为的主要杠杆。

### 提示工程的八大原则

#### 1. 像你的智能体一样思考

**核心思想**：要迭代提示，必须理解其效果。

**实践方法**：
- 使用 Console 构建模拟
- 使用与系统完全相同的提示和工具
- 逐步观察智能体工作

**发现的问题**：
- 智能体在有足够结果时继续执行
- 使用过于冗长的搜索查询
- 选择错误的工具

**关键洞察**：有效的提示依赖于对智能体准确的思维模型，这使得最有影响力的变化变得显而易见。

#### 2. 教导编排器如何委派

**系统中的角色**：
- 主导智能体：将查询分解为子任务并描述给子智能体
- 每个子智能体需要：
  - 明确的目标
  - 输出格式
  - 工具和来源使用指导
  - 清晰的任务边界

**失败的教训**：
- 最初允许主导智能体给出简单、简短的指令（如"研究半导体短缺"）
- 这些指令往往过于模糊
- 子智能体误解任务或执行与其他智能体完全相同的搜索

**具体失败案例**：
- 一个子智能体探索 2021 年汽车芯片危机
- 另外两个重复工作调查当前 2025 年供应链
- 缺乏有效的劳动分工

#### 3. 根据查询复杂度扩展工作量

**问题**：智能体难以判断不同任务的适当工作量。

**解决方案**：在提示中嵌入扩展规则。

| 任务类型 | 智能体数量 | 每个智能体的工具调用次数 |
|---------|-----------|------------------------|
| 简单事实查找 | 1 | 3-10 |
| 直接比较 | 2-4 | 10-15 |
| 复杂研究 | >10 | 责任明确划分 |

**效果**：这些明确指导原则帮助主导智能体高效分配资源，防止在简单查询中过度投入（这是早期版本的常见失败模式）。

#### 4. 工具设计和选择至关重要

**关键类比**：智能体-工具接口与人类-计算机接口同样关键。

**使用正确的工具**：
- 高效且往往是严格必要的
- 例如：在网页上搜索仅存在于 Slack 中的上下文注定会失败

**MCP 服务器的挑战**：
- 智能体遇到未见过的工具
- 工具描述质量参差不齐

**解决方案**：给智能体明确的启发式规则

| 启发式规则 | 说明 |
|-----------|------|
| 首先检查所有可用工具 | 避免遗漏最佳工具 |
| 将工具使用与用户意图匹配 | 确保相关性 |
| 网页搜索用于广泛的外部探索 | 广泛探索时优先 |
| 优先使用专业工具而非通用工具 | 提高效率 |

**关键要求**：
- 每个工具需要有明确的目的
- 每个工具需要清晰的描述
- 糟糕的工具描述可能让智能体走完全错误的方向

#### 5. 让智能体自我改进

**发现**：Claude 4 模型可以是优秀的提示工程师。

**能力**：给定提示和失败模式时，模型能够：
- 诊断智能体失败的原因
- 建议改进

**创新实践**：创建工具测试智能体

```
给定有缺陷的 MCP 工具
   ↓
尝试使用工具
   ↓
重写工具描述以避免失败
   ↓
通过数十次测试发现关键细微差别和错误
```

**效果**：改进工具工效学的过程：
- 导致未来使用新描述的智能体任务完成时间减少 **40%**
- 因为它们能够避免大多数错误

#### 6. 先宽后窄

**原则**：搜索策略应模仿专家人类研究：在深入细节之前探索景观。

**问题**：智能体往往默认使用过长、过于具体的查询，返回很少的结果。

**解决方案**：通过提示引导智能体：
1. 从简短、广泛的查询开始
2. 评估可用内容
3. 逐步缩小焦点

#### 7. 引导思考过程

**扩展思考模式**：让 Claude 在可见的思考过程中输出额外的 token，可作为可控的草稿纸。

**主导智能体的思考应用**：
- 制定方法
- 评估哪些工具适合任务
- 确定查询复杂度和子智能体数量
- 定义每个子智能体的角色

**测试结果**：扩展思考改善了：
- 指令遵循
- 推理
- 效率

**子智能体的交错思考**：
- 工具结果之后使用交错思考
- 评估质量
- 识别差距
- 优化下一个查询

**效果**：使子智能体在适应任何任务方面更加有效。

#### 8. 并行工具调用改变速度和性能

**问题的本质**：复杂研究任务自然涉及探索许多来源。

**早期方式**：顺序搜索， painfully slow（极其缓慢）。

**两种并行化加速**：

| 并行类型 | 实现方式 | 效果 |
|---------|---------|------|
| 智能体级并行 | 主导智能体并行启动 3-5 个子智能体 | 避免序列化等待 |
| 工具级并行 | 子智能体并行使用 3+ 工具 | 加速信息收集 |

**性能提升**：
- 复杂查询的研究时间减少高达 **90%**
- Research 可以在几分钟内完成需要其他系统数小时的工作
- 覆盖比其他系统更多的信息

### 提示策略的核心思想

Anthropic 的提示策略侧重于灌输**良好的启发式规则**而非刚性规则。

**编码的人类研究策略**：
- 将困难问题分解为更小的任务
- 仔细评估来源质量
- 根据新信息调整搜索方法
- 识别何时专注于深度（详细调查一个主题）vs 广度（并行探索许多主题）

**保障措施**：
- 主动减轻意外副作用
- 设置明确的安全护栏
- 防止智能体失控

**迭代循环**：
- 快速迭代循环
- 可观察性
- 测试用例

---

## 智能体的有效评估方法

### 评估的独特挑战

传统评估假设 AI 每次遵循相同步骤：给定输入 X，系统应遵循路径 Y 产生输出 Z。

**多智能体系统的不同之处**：
- 即使起点相同，智能体可能采取完全不同的有效路径达成目标
- 一个智能体可能搜索 3 个来源，另一个搜索 10 个
- 它们可能使用不同的工具找到相同的答案

**挑战**：由于我们并不总是知道正确的步骤，不能只检查智能体是否遵循预先规定的"正确"步骤。

**解决方案**：需要灵活的评估方法，判断智能体是否达成了正确的**结果**，同时遵循合理的过程。

### 评估的三大方法

#### 1. 立即开始评估（小样本）

**关键洞察**：在早期智能体开发中，变化往往产生剧烈影响。

**效果大小示例**：
- 提示调整可能将成功率从 30% 提升到 80%

**策略**：
- 从约 20 个代表真实使用模式的查询开始
- 测试这些查询通常能够清楚地看到变化的影响

**常见误解**：AI 开发团队经常延迟创建评估，因为他们认为只有数百个测试用例的大规模评估才有用。

**最佳实践**：立即从小规模测试开始，只用几个例子，而不是等到能够构建更全面的评估。

#### 2. LLM-as-Judge 评估（规模化）

**问题**：研究输出难以通过编程评估，因为它们是自由形式文本，很少有一个正确答案。

**解决方案**：LLM 是评分输出的自然选择。

**评分标准（评分量表）**：

| 标准 | 说明 |
|------|------|
| 事实准确性 | 声明是否与来源匹配？ |
| 引用准确性 | 引用的来源是否与声明匹配？ |
| 完整性 | 是否覆盖了所有要求的方面？ |
| 来源质量 | 是否使用主要来源而非低质量的次要来源？ |
| 工具效率 | 是否合理次数地使用正确的工具？ |

**实现细节**：
- 尝试使用多个评审员评估每个组件
- 发现：**单个 LLM 调用**输出 0.0-1.0 的分数和通过/失败等级是最一致的
- 与人类判断最一致

**特别有效的场景**：评估测试用例**确实**有清晰答案时
- LLM 评审员可以简单地检查答案是否正确
- 例如：是否准确列出了研发预算前 3 大的制药公司？

**规模化能力**：使用 LLM 作为评审员可以可扩展地评估数百个输出。

#### 3. 人类评估（捕捉自动化遗漏）

**人类测试员发现的边缘案例**：
- 非常规查询的幻觉答案
- 系统故障
- 微妙的来源选择偏差

**Anthropic 的发现**：
- 人类测试员注意到早期智能体始终选择 SEO 优化的内容农场
- 而非权威但排名较低的来源（如学术 PDF 或个人博客）

**解决方案**：在提示中添加来源质量启发式规则帮助解决了这个问题。

**关键结论**：即使在自动化评估的世界中，手动测试仍然必不可少。

### 涌现行为的处理

**涌现行为**：在没有特定编程的情况下产生的行为。

**例子**：主导智能体的微小变化可能不可预测地改变子智能体的行为方式。

**成功的关键**：
- 理解交互模式，而不仅仅是个体智能体行为
- 最好的提示不仅仅是严格的指令
- 而是协作的框架，定义：
  - 劳动分工
  - 问题解决方法
  - 工作量预算

**实现正确需要**：
- 仔细的提示和工具设计
- 坚实的启发式规则
- 可观察性
- 紧密的反馈循环

**参考资源**：Anthropic Cookbook 中的[开源提示](https://platform.claude.com/cookbook/patterns-agents-basic-workflows)

---

## 生产可靠性与工程挑战

### 智能体系统与传统软件的差异

在传统软件中，bug 可能会：
- 破坏功能
- 降低性能
- 导致中断

在智能体系统中：
- 微小的变化级联成大的行为变化
- 这使得为必须在长期运行过程中维护状态的复杂智能体编写代码变得极其困难

### 四大核心工程挑战

#### 1. 智能体是有状态的，错误会复合

**问题特征**：
- 智能体可以运行很长时间
- 在许多工具调用之间维护状态
- 需要持久执行代码并沿途处理错误

**风险**：没有有效的缓解措施，微小的系统故障对智能体可能是灾难性的。

**解决方案**：

| 策略 | 说明 |
|------|------|
| 恢复机制 | 当错误发生时，不能只从头开始重新启动（昂贵且令人沮丧） |
| 从故障点恢复 | 构建可以从智能体出错时恢复的系统 |
| 智能适应 | 使用模型的智能优雅地处理问题<br>• 让智能体知道工具何时失败<br>• 让它适应（效果出奇地好） |
| 确定性保障 | 结合：重试逻辑 + 定期检查点 |

**方法**：将 AI 智能体的适应性与确定性保障相结合。

#### 2. 调试需要新方法

**问题**：
- 智能体做出动态决策
- 即使提示相同，运行之间也是不确定的
- 这使得调试更加困难

**实际案例**：用户报告智能体"没有找到明显信息"，但无法看到原因

**潜在原因**：
- 智能体使用糟糕的搜索查询？
- 选择糟糕的来源？
- 遇到工具故障？

**解决方案**：
- 添加完整的生产跟踪
- 诊断智能体失败的原因
- 系统性地修复问题
- 监控智能体决策模式和交互结构（不监控个人对话内容，以保护用户隐私）
- 这种高级别可观察性有助于：
  - 诊断根本原因
  - 发现意外行为
  - 修复常见故障

#### 3. 部署需要仔细协调

**系统特征**：
- 高度有状态：提示、工具和执行逻辑的网
- 几乎连续运行
- 部署更新时，智能体可能处于过程的任何位置

**挑战**：防止善意的代码更改破坏现有的智能体

**解决方案**：使用 **Rainbow Deployments（彩虹部署）**

| 部署策略 | 说明 |
|---------|------|
| 同时运行 | 同时保持新旧版本运行 |
| 渐进流量转移 | 逐渐将流量从旧版本转移到新版本 |
| 避免中断 | 避免中断正在运行的智能体 |

**限制**：不能同时将每个智能体更新到新版本。

#### 4. 同步执行造成瓶颈

**当前实现**：
- 主导智能体同步执行子智能体
- 等待每组子智能体完成后再继续

**优点**：简化协调

**缺点**：造成智能体之间信息流的瓶颈

**瓶颈表现**：
- 主导智能体无法引导子智能体
- 子智能体无法协调
- 整个系统可能在等待单个子智能体完成搜索时被阻塞

**未来方向**：异步执行

| 优势 | 挑战 |
|------|------|
| • 额外的并行性<br>• 智能体并发工作<br>• 需要时创建新子智能体 | • 结果协调<br>• 状态一致性<br>• 子智能体之间的错误传播 |

**前景**：随着模型能够处理更长、更复杂的研究任务，性能提升将证明复杂性是合理的。

---

## 结论

### 原型与生产的差距

当构建 AI 智能体时，"最后一英里"往往成为大部分旅程。

**从开发者机器到生产**：
- 在开发者机器上工作的代码库需要大量工程才能成为可靠的生产系统
- 智能体系统中错误的复合性质意味着传统软件的次要问题可能完全使智能体偏离轨道
- 一个步骤失败可能导致智能体探索完全不同的轨迹，导致不可预测的结果

**差距原因**：
- 原型与生产之间的差距往往比预期的要宽

### 多智能体系统的价值

尽管面临挑战，多智能体系统已被证明对开放式研究任务有价值。

**用户反馈**：
- Claude 帮助他们找到以前没有考虑过的商业机会
- 导航复杂的医疗保健选择
- 解决棘手的技术错误
- 通过发现他们独自不会找到的研究联系节省多达数天的工作

### 成功的关键要素

多智能体研究系统可以通过以下方式在规模上可靠运行：

| 要素 | 说明 |
|------|------|
| 精心工程 | 仔细的架构设计和实现 |
| 全面测试 | 多层次的评估和验证 |
| 细致的提示和工具设计 | 注重工效学和明确性 |
| 健壮的操作实践 | 监控、跟踪和部署策略 |
| 紧密协作 | 研究、产品和工程团队之间的密切合作<br>需要对当前智能体能力有深刻理解 |

### 当前使用情况

根据 Clio 嵌入绘图，Research 功能最常见的使用类别：

| 使用类别 | 占比 |
|---------|------|
| 开发跨专业领域的软件系统 | 10% |
| 开发和优化专业和技术内容 | 8% |
| 制定业务增长和收入生成策略 | 8% |
| 协助学术研究和教育材料开发 | 7% |
- 研究和验证关于人员、地点或组织的信息 | 5% |

### 未来展望

Anthropic 已经看到这些系统正在改变人们解决复杂问题的方式。

---

## 附录：额外技巧

### 1. 评估在多回合中改变状态的智能体

**问题**：评估在多回合对话中修改持久状态的智能体面临独特挑战。

| 区别 | 只读研究任务 | 状态修改任务 |
|------|------------|------------|
| 依赖关系 | 低 | 高（每步都改变后续环境） |
| 评估方法 | 逐步分析 | 终态评估 |

**成功策略**：专注于**终态评估**而非逐步分析。

| 方法 | 说明 |
|------|------|
| 结果导向 | 评估是否达到正确的最终状态，而非是否遵循特定过程 |
| 承认替代路径 | 智能体可能找到通往同一目标的替代路径 |
| 检查点评估 | 对于复杂工作流，将评估分解为离散检查点<br>• 特定状态变化应该发生的点<br>• 而非尝试验证每个中间步骤 |

### 2. 长期对话管理

**挑战**：生产智能体经常参与跨越数百回合的对话，需要仔细的上下文管理策略。

**问题**：
- 随着对话扩展，标准上下文窗口变得不足
- 需要智能压缩和记忆机制

**实现模式**：

| 模式 | 说明 |
|------|------|
| 阶段总结 | 智能体总结已完成的工作阶段 |
| 外部记忆存储 | 在继续新任务之前将重要信息存储在外部记忆中 |
| 清爽上下文的子智能体 | 当上下文限制接近时<br>• 智能体可以生成具有清爽上下文的新子智能体<br>• 通过仔细移交保持连续性 |
| 记忆检索 | 可以从记忆中检索存储的上下文（如研究计划）<br>• 而非在达到上下文限制时丢失先前工作 |

**效果**：这种分布式方法防止上下文溢出，同时在扩展交互中保持对话连贯性。

### 3. 子智能体输出到文件系统以最小化"传话游戏"

**问题**：
- 直接子智能体输出必须通过主导智能体
- 可能导致信息失真

**"传话游戏"问题**：
- 信息在多阶段处理过程中丢失
- 通过对话历史复制大输出导致 token 开销

**解决方案**：工件系统

| 工件系统模式 | 说明 |
|------------|------|
| 直接输出 | 专业智能体可以创建独立持久化的输出 |
| 外部存储 | 子智能体调用工具将其工作存储在外部系统中 |
| 轻量级引用 | 将轻量级引用传递给协调器 |
| 避免过滤 | 专业智能体的专业提示产生比通过通用协调器过滤更好的结果 |

**特别适用的输出类型**：
- 代码
- 报告
- 数据可视化

**效果**：这种模式对于结构化输出特别有效，其中子智能体的专业提示产生比通过通用协调器过滤更好的结果。

---

## 核心洞察总结

### 架构原则

1. **编排器-工作器模式**：主导智能体协调，子智能体并行执行
2. **独立上下文窗口**：每个智能体有独立的思考空间
3. **持久化记忆**：关键信息存储在外部记忆中，避免上下文截断

### Token 与性能的关系

```
性能 ≈ f(Token 使用量, 工具调用数, 模型选择)
其中 Token 使用量解释 80% 的方差
```

### 提示工程核心

| 原则 | 核心思想 |
|------|---------|
| 像智能体一样思考 | 理解提示的实际效果 |
| 教会委派 | 明确目标、格式、工具、边界 |
| 按复杂度扩展 | 简单任务少用资源，复杂任务多用 |
| 工具设计至关重要 | 明确目的 + 清晰描述 |
| 自我改进 | 利用模型优化提示和工具描述 |
| 先宽后窄 | 先探索景观，再深入细节 |
| 引导思考 | 使用扩展思考和交错思考 |
| 并行化 | 智能体级 + 工具级并行 |

### 评估策略

1. **立即开始**：小样本评估，迭代快速
2. **LLM-as-Judge**：规模化评估，使用评分量表
3. **人工评估**：捕捉边缘案例和微妙问题

### 生产可靠性

| 挑战 | 解决方案 |
|------|---------|
| 状态复合 | 恢复机制 + 智能适应 + 确定性保障 |
| 调试困难 | 生产跟踪 + 高级可观察性 |
| 部署协调 | Rainbow Deployments |
| 同步瓶颈 | 未来转向异步执行 |

### 适用场景

**✅ 适合**：
- 高价值任务
- 大量并行化需求
- 信息超过单个上下文窗口
- 需要与众多复杂工具交互

**❌ 不适合**：
- 需要共享相同上下文的任务
- 智能体之间高度依赖
- 编码任务（通常可并行化任务较少）

### 成本考量

```
智能体 ≈ 4× 聊天交互 Token
多智能体系统 ≈ 15× 聊天交互 Token
```

### 关键性能指标

- **复杂查询研究时间减少**：高达 90%
- **多智能体 vs 单智能体**：内部评估提升 90.2%
- **工具描述优化**：任务完成时间减少 40%

---

## 作者与致谢

**作者**：
- Jeremy Hadfield
- Barry Zhang
- Kenneth Lien
- Florian Scholz
- Jeremy Fox
- Daniel Ford

**特别感谢**：
- Anthropic 应用程序工程团队，致力于将这个复杂的多智能体系统投入生产
- 早期用户提供的出色反馈

---

## 相关资源

- [Research 功能发布公告](https://www.anthropic.com/news/research)
- [Anthropic Cookbook - 智能体基本工作流](https://platform.claude.com/cookbook/patterns-agents-basic-workflows)
- [扩展思考模式文档](https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking)
- [交错思考文档](https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking#interleaved-thinking)
- [MCP 服务器介绍](https://modelcontextprotocol.io/introduction)
- [BrowseComp 评估](https://openai.com/index/browsecomp/)
- [Clio 研究](https://www.anthropic.com/research/clio)
- [Rainbow Deployments](https://brandon.dimcheff.com/2018/02/rainbow-deploys-with-kubernetes/)
- [Console](https://console.anthropic.com/)

---

*文档分析完成日期：2026年2月11日*
