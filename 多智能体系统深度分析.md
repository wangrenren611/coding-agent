# 构建多智能体系统：何时以及如何使用
## —— 深度分析报告

---

## 文章基本信息

| 属性 | 内容 |
|------|------|
| **标题** | Building multi-agent systems: when and how to use them（构建多智能体系统：何时以及如何使用） |
| **作者** | Cara Phillips（主要作者）<br>贡献者：Paul Chen, Andy Schumeister, Brad Abrams, Theo Chu |
| **发布时间** | 2026年1月23日 |
| **阅读时长** | 5分钟 |
| **发布平台** | Claude 官方博客 |
| **文章分类** | Agents（智能体） |
| **相关产品** | Claude Developer Platform, Claude Code |

---

## 一、文章概述

### 1.1 核心观点

**"多智能体系统是强大的，但并非普适适用"**

本文的核心论点是：虽然多智能体架构可以为组织解锁额外价值，但它们通常被应用在单一智能体表现更好的场景中。文章明确指出——在决定采用多智能体架构之前，应该从最简单的有效方法开始，只有当证据支持时才增加复杂性。

### 1.2 文章结构

1. **单智能体优先原则** — 为什么要从单智能体开始
2. **多智能体决策框架** — 三大适用场景
3. **超越单智能体架构的信号** — 何时应该升级
4. **以上下文为中心的分解** — 如何正确分割工作
5. **验证子智能体模式** — 一个始终有效的模式
6. **前进方向** — 总结与建议

---

## 二、深度内容解析

### 2.1 多智能体系统定义

文章给出了明确定义：

> 多智能体系统是一种架构，其中多个LLM实例在独立的对话上下文中运行，通过代码进行协调。

文章专注于**编排者-子智能体模式**（orchestrator-subagent pattern）：
- 分层模型
- 主导智能体生成和管理专门的子智能体
- 子智能体处理特定子任务

这是多智能体系统入门的良好起点。

### 2.2 单智能体优先原则

#### 问题现状

许多团队投入数月构建复杂的多智能体架构，结果发现对单一智能体进行改进的提示词（prompting）就能达到等效效果。

#### 多智能体系统的开销

| 开销类型 | 说明 |
|---------|------|
| **潜在故障点** | 每个额外的智能体都是另一个可能失败的环节 |
| **提示词维护** | 需要维护多套提示词 |
| **意外行为** | 更多的不可预测行为来源 |

#### 实测数据

> 在我们的测试中，对于等效任务，多智能体实现通常比单智能体方法使用**3-10倍**的token。

开销来源：
- 跨智能体重复上下文
- 智能体之间的协调消息
- 交接时总结结果

### 2.3 三大适用场景

#### 场景一：上下文保护（Context Protection）

**问题背景**：
大语言模型有有限的上下文窗口，随着上下文增长，响应质量会下降。当智能体的上下文积累来自一个子任务的信息，但这些信息与后续子任务无关时，就会发生**上下文污染**。

**解决方案**：
子智能体提供隔离，每个智能体在自己的干净上下文中运行，专注于特定任务。

**实际案例**：客户支持智能体

单智能体方法的问题：
```javascript
# 单智能体在上下文中积累所有内容
conversation_history = [
    {"role": "user", "content": "我的订单#12345无法工作"},
    {"role": "assistant", "content": "让我检查您的订单..."},
    # 工具结果添加了2000+ token的订单历史
    {"role": "user", "content": "...(订单详情、过往购买、配送信息)..."},
    {"role": "assistant", "content": "现在让我诊断技术问题..."},
    # 上下文现在被智能体不需要的订单细节污染了
]
```

多智能体方法的优势：
```python
from anthropic import Anthropic

class OrderLookupAgent:
    def lookup_order(self, order_id: str) -> dict:
        # 独立智能体，有自己的上下文
        # 返回仅包含必要信息的摘要
        return extract_summary(response)

class SupportAgent:
    def handle_issue(self, user_message: str):
        # 主智能体上下文保持干净
        # 只接收50-100个token的摘要
        order_summary = OrderLookupAgent().lookup_order(order_id)
        context = f"订单{order_id}: {order_summary['status']}, 购买于{order_summary['date']}"
```

**适用条件**：
- 子任务生成大量上下文（超过1000 token）但大部分信息与主任务无关
- 子任务定义清晰，有明确的信息提取标准
- 需要过滤后再使用的查找或检索操作

#### 场景二：并行化（Parallelization）

**核心价值**：
运行多个并行智能体可以比单个智能体覆盖更大的搜索空间。这对搜索和研究任务特别有价值。

**实际应用**：
Claude的研究功能使用这种方法：
1. 主导智能体分析查询
2. 生成多个子智能体并行调查不同方面
3. 每个子智能体独立搜索
4. 返回提炼的发现
5. 主导智能体综合结果

**代码示例**：
```python
import asyncio
from anthropic import AsyncAnthropic

async def research_topic(query: str) -> dict:
    # 主导智能体将查询分解为研究方面
    facets = await lead_agent.decompose_query(query)

    # 生成子智能体并行研究每个方面
    tasks = [research_subagent(facet) for facet in facets]
    results = await asyncio.gather(*tasks)

    # 主导智能体综合发现
    return await lead_agent.synthesize(results)
```

**权衡分析**：

| 优势 | 代价 |
|-----|------|
| 更大的搜索空间覆盖 | Token使用增加3-10倍 |
| 更全面的结果 | 总执行时间通常更长 |
| 多角度探索 | 需要协调多个上下文 |

**重要澄清**：
并行化的主要好处是**全面性，而非速度**。当需要搜索大型信息空间或调查复杂问题的多个角度时，并行智能体可以比单智能体覆盖更多领域。

#### 场景三：专业化（Specialization）

#### 2.3.3.1 工具集专业化

当智能体访问过多工具时，性能会下降。三个信号表明工具专业化会有帮助：

1. **数量过多** — 拥有过多工具（通常20+）的智能体难以选择合适的工具
2. **领域混淆** — 工具跨越多个不相关领域（数据库操作、API调用、文件系统操作），智能体混淆哪个领域适用于给定任务
3. **性能下降** — 添加新工具会降低现有任务的性能

#### 2.3.3.2 系统提示词专业化

不同任务有时需要不同的人格、约束或指令，这些在组合时会产生冲突：

| 任务类型 | 所需特质 | 冲突点 |
|---------|---------|-------|
| 客户支持 | 同理心、耐心 | vs 代码审查的精确和批判 |
| 代码审查 | 精确、批判 | vs 头脑风暴的创意灵活性 |
| 合规检查 | 严格规则遵循 | vs 创意发散的思维模式 |

#### 2.3.3.3 领域专业知识专业化

某些任务受益于深度领域上下文，但这会压倒通用智能体：
- 法律分析智能体需要大量案例法和监管框架上下文
- 医学研究智能体需要专门的临床试验方法论知识

**实际案例**：多平台集成

单一智能体问题：
- 需要40+工具（CRM、营销自动化、消息平台，各10-15个API端点）
- 经常难以正确选择
- 跨平台混淆相似操作

专业化解决方案：
```python
class CRMAgent:
    """处理客户关系管理操作"""
    system_prompt = """你是CRM专家。你管理联系人、商机和账户记录。
    更新前始终验证记录所有权，并保持相关记录的数据完整性。"""
    tools = [crm_get_contacts, crm_create_opportunity, ...]

class MarketingAgent:
    """处理营销自动化操作"""
    system_prompt = """你是营销自动化专家。你管理活动、线索评分和邮件序列。
    优先考虑数据卫生并尊重联系人偏好。"""
    tools = [marketing_get_campaigns, marketing_create_lead, ...]

class OrchestratorAgent:
    """路由请求到专门的智能体"""
    def execute(self, user_request: str):
        # 路由逻辑
        pass
```

**专业化权衡**：
- 路由复杂性：编排者必须正确分类请求并委托给正确的智能体
- 提示词维护开销增加
- 最佳适用条件：领域明确可分离且路由决策明确

### 2.4 超越单智能体架构的信号

#### 信号1：接近上下文限制
- 智能体定期使用大量上下文且性能下降
- 注意：上下文管理的新进展（如自动压缩）正在减少这一限制

#### 信号2：管理许多工具
- 智能体有15-20+工具时，模型花费大量上下文理解选项
- 建议先尝试工具搜索工具，可减少高达85%的token使用

#### 信号3：可并行化的子任务
- 任务自然分解为独立部分（跨多个来源的研究、多个组件的测试）
- 并行子智能体可提供显著加速

**重要提示**：这些阈值会随着模型改进而变化。当前限制代表实践指导原则，而非根本约束。

### 2.5 以上下文为中心的分解

#### 核心设计原则

**关键洞察**：在分解工作时，应采用**以上下文为中心的视角**而非以问题为中心的视角。

#### 对比分析

| 分解方式 | 描述 | 评价 |
|---------|------|------|
| **以问题为中心**（通常适得其反） | 按工作类型划分（一个智能体写功能，另一个写测试，第三个审查代码） | ❌ 产生持续协调开销，每次交接都会丢失上下文 |
| **以上下文为中心**（通常有效） | 按上下文边界划分（处理功能的智能体也处理其测试） | ✅ 智能体已拥有必要的上下文，只在可以真正隔离上下文时才分割工作 |

#### "电话游戏"问题

当智能体按问题类型划分时，它们会进行"电话游戏"，信息来回传递时每次交接都会降低保真度。

实验观察：在一个按软件开发角色（规划者、实施者、测试者、审查者）专业化的智能体实验中，子智能体在协调上花费的token比实际工作还多。

#### 有效分解边界

✅ **良好的边界**：
- 独立的研究路径（如"亚洲市场趋势" vs "欧洲市场趋势"）
- 具有清晰接口的独立组件（如前端和后端工作）
- 黑盒验证（只需运行测试并报告结果的验证者）

❌ **不当的边界**：
- 同一工作的连续阶段（规划、实施和测试同一功能共享太多上下文）
- 紧密耦合的组件（需要频繁来回交流的组件应保持在同一智能体中）
- 需要共享状态的工作（需要频繁同步理解的智能体应保持在一起）

### 2.6 验证子智能体模式

#### 模式定义

**验证子智能体**是一个多智能体模式，在各个领域始终表现良好。这是一个专门的智能体，其唯一职责是测试或验证主智能体的工作。

#### 为什么有效

验证子智能体之所以成功，是因为它们绕过了"电话游戏"问题：
- 验证本质上有最小的上下文传输需求
- 验证者可以在不需要完整构建历史的情况下黑盒测试系统

#### 实现示例

```python
from anthropic import Anthropic

class CodingAgent:
    def implement_feature(self, requirements: str) -> dict:
        """主智能体实现功能"""
        # 实现代码
        pass

class VerificationAgent:
    def verify_implementation(self, requirements: str, files_changed: list) -> dict:
        """单独的智能体验证工作"""
        messages = [{"role": "user", "content": f"""
需求: {requirements}
更改的文件: {files_changed}

运行测试套件并验证：
1. 所有现有测试通过
2. 新功能按指定工作
3. 没有明显的错误或安全问题

你必须在标记为通过之前运行完整的测试套件。
不要在只运行几个测试后标记为通过。
运行：pytest --verbose
只有在所有测试通过且没有失败时才标记为PASSED。
        """}]
        pass

def implement_with_verification(requirements: str, max_attempts: int = 3):
    for attempt in range(max_attempts):
        result = CodingAgent().implement_feature(requirements)
        verification = VerificationAgent().verify_implementation(
            requirements, result['files_changed']
        )

        if verification['passed']:
            return result

        requirements += f"\n\n之前的尝试失败: {verification['issues']}"

    raise Exception(f"在{max_attempts}次尝试后验证失败")
```

#### 应用场景

| 场景 | 用途 |
|-----|------|
| **质量保证** | 运行测试套件、代码检查、根据架构验证输出 |
| **合规检查** | 验证文档符合策略要求、根据规则检查输出 |
| **输出验证** | 在交付前确认生成的内容符合规格 |
| **事实验证** | 让单独的智能体验证生成内容中的声明或引用 |

#### "早期胜利"问题

**最大失败模式**：验证子智能体在未彻底测试的情况下将输出标记为通过。验证者运行一两个测试，观察它们通过，然后声明成功。

**缓解策略**：
1. **具体标准** — 指定"运行完整测试套件并报告所有失败"而非"确保它工作"
2. **全面检查** — 要求验证者测试多个场景和边缘情况
3. **负面测试** — 指导验证者尝试应该失败的输入并确认它们确实失败
4. **明确指令** — "你必须在标记为通过之前运行完整的测试套件"这一指令至关重要

---

## 三、核心观点总结

### 3.1 决策检查清单

在采用多智能体架构之前，确认：

| 检查项 | 说明 |
|-------|------|
| 1. 存在真正的约束 | 多智能体可以解决的实际约束，如上下文限制、并行化机会或专业化需求 |
| 2. 分解遵循上下文而非问题类型 | 按所需的上下文分组工作，而非工作类型 |
| 3. 存在明确的验证点 | 子智能体可以在不需要完整上下文的情况下验证工作 |

### 3.2 实践建议

> "我们的建议是从最简单的有效方法开始，只有当证据支持时才增加复杂性。"

### 3.3 相关资源链接

1. [构建有效智能体](https://www.anthropic.com/engineering/building-effective-agents) — 单智能体模式
2. [AI智能体的有效上下文工程](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents) — 上下文管理策略
3. [我们如何构建多智能体研究系统](https://www.anthropic.com/engineering/multi-agent-research-system) — 多智能体研究系统深度解析

---

## 四、深度评析

### 4.1 文章价值

这篇文章提供了非常实用的技术指导，其价值体现在：

1. **反直觉的洞察**：挑战了"多智能体总是更好"的假设，强调简单性优先
2. **数据驱动**：提供具体的性能数据（3-10倍token开销）支持论点
3. **模式识别**：总结出三大明确适用场景和有效/无效的分解模式
4. **代码示例**：提供可执行的实际代码展示概念
5. **务实态度**：强调"从简单开始，证据驱动升级"的理念

### 4.2 技术洞察

#### 上下文管理是关键
文章反复强调上下文污染问题，这是当前LLM架构的核心瓶颈。随着上下文窗口增大和压缩技术发展，这一限制会逐渐减弱。

#### 并行化的真正价值
澄清了一个重要误解：并行化主要贡献是全面性而非速度。这对于设计多智能体系统时设定正确期望非常重要。

#### "电话游戏"问题
这个比喻非常生动地说明了多智能体系统中信息传递的质量衰减问题。这应该成为架构设计时的核心考量。

### 4.3 实施难点

1. **路由复杂性**：专业化智能体需要可靠的编排者进行路由，这本身可能成为瓶颈
2. **调试困难**：多智能体系统的行为更难调试和追踪
3. **成本管理**：3-10倍的token开销意味着显著的成本增加
4. **维护负担**：多个提示词、多个智能体的配置增加了系统复杂性

### 4.4 未来展望

文章提到的几个发展方向值得关注：
- 上下文压缩技术减少上下文限制的影响
- 工具搜索工具动态发现工具，减少前向加载的开销
- 更强大的编排者模型（如Claude Opus 4.5）可能直接评估子智能体工作，无需单独验证步骤

---

## 五、关键金句摘录

1. "今天，多智能体系统经常应用在单一智能体会表现更好的情况中。"
2. "多智能体系统通常比单智能体方法使用3-10倍的token。"
3. "采用以上下文为中心的视角，而非以问题为中心的视角。"
4. "并行化的主要好处是全面性，而非速度。"
5. "我们的建议是从最简单的有效方法开始，只有当证据支持时才增加复杂性。"

---

## 六、作者背景与贡献

### 主要作者：Cara Phillips
- Anthropic工程师
- 撰写关于智能体系统的技术博客
- 参与多智能体系统架构设计和实践

### 贡献者
| 姓名 | 可能角色 |
|-----|---------|
| Paul Chen | 可能是工程师或研究员 |
| Andy Schumeister | 可能是工程师或研究员 |
| Brad Abrams | 资深产品/工程角色 |
| Theo Chu | 可能是工程师或研究员 |

---

## 七、总结与建议

### 对开发者的建议

1. **从单智能体开始** — 除非有明确的约束需要多智能体解决方案
2. **以证据驱动决策** — 不要因为"更先进"而采用复杂架构
3. **关注上下文边界** — 分解工作时要考虑上下文需求，而非工作类型
4. **考虑验证模式** — 验证子智能体是多智能体系统中少数"安全"的模式之一
5. **监控性能成本** — 准备应对3-10倍的token开销

### 对架构师的建议

1. **评估上下文压力** — 这是采用多智能体系统最可靠的信号
2. **考虑专业化边界** — 清晰分离的领域适合专业化智能体
3. **规划路由策略** — 编排者的路由可靠性决定系统成功与否
4. **设计验证点** — 明确的验证检查点是成功多智能体系统的关键

### 对技术决策者的建议

1. **投资简单解决方案** — 在增加复杂性之前，先优化单智能体架构
2. **设定成功指标** — 明确的ROI指标来证明多智能体投资的合理性
3. **建立监控** - 跟踪token使用、响应质量和系统可靠性
4. **渐进演进** — 从验证子智能体等低风险模式开始

---

**文档生成时间**: 2026年2月10日
**分析基于**: Claude官方博客文章 "Building multi-agent systems: when and how to use them"
